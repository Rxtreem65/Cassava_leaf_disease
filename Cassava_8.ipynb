{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS5FwOWbuOSI",
        "outputId": "3b3f537e-2825-4401-cba5-31f1a41f6893"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jan  8 09:55:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZLCnTnQuci6"
      },
      "source": [
        "#loading all the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import random\n",
        "\n",
        "import os\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y68FK-H8ugHV",
        "outputId": "31f7f5af-62e7-42cd-9362-cddced3da193"
      },
      "source": [
        "image_path=\"/content/drive/MyDrive/Datasets/cassava-leaf-disease-classification\"\n",
        "\n",
        "#mapping the class names with labels\n",
        "with open(os.path.join(image_path, \"label_num_to_disease_map.json\")) as file:\n",
        "    map_classes = json.loads(file.read())\n",
        "    map_classes = {int(k) : v for k, v in map_classes.items()}\n",
        "    \n",
        "print(json.dumps(map_classes, indent=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"0\": \"Cassava Bacterial Blight (CBB)\",\n",
            "    \"1\": \"Cassava Brown Streak Disease (CBSD)\",\n",
            "    \"2\": \"Cassava Green Mottle (CGM)\",\n",
            "    \"3\": \"Cassava Mosaic Disease (CMD)\",\n",
            "    \"4\": \"Healthy\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh06KrAkuiy0"
      },
      "source": [
        "#Split the data into train, valid, test\n",
        "df_data = pd.read_csv(os.path.join(image_path, \"train.csv\"))\n",
        "df_data[\"class_name\"] = df_data[\"label\"].map(map_classes)\n",
        "\n",
        "df  = pd.read_csv(image_path+\"/train.csv\")\n",
        "\n",
        "df[\"path\"] = df['image_id'].map(lambda x: image_path+\"/train_images/\"+x)\n",
        "df = df.drop(columns=['image_id'])\n",
        "df= df.sample(frac=1).reset_index(drop=True) #for random sample assignment\n",
        "\n",
        "train = int(len(df) * 0.7) #70%\n",
        "valid = int(len(df) * 0.2) #20%\n",
        "test = len(df)-train-valid #10%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq0Hj9C6ulCZ"
      },
      "source": [
        "train_df = df[:train]\n",
        "valid_df = df[train + 1:valid+train].reset_index().drop(columns = ['index'])\n",
        "test_df = df[train+valid+1:].reset_index().drop(columns = ['index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNPlFEunKn"
      },
      "source": [
        "#defining the transformation of the data\n",
        "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                transforms.CenterCrop((256,256)),\n",
        "                                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                transforms.RandomVerticalFlip(p=0.5)\n",
        "                                ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLt7J7f3uo5U"
      },
      "source": [
        "#defining the Preprossesing the data into image and label\n",
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform = None):\n",
        "        super().__init__()\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df[\"path\"])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # get path and label\n",
        "        path = self.df[\"path\"][index]\n",
        "        label = self.df[\"label\"][index]\n",
        "        # load image\n",
        "        with open(path, 'rb') as f:\n",
        "            image = Image.open(f)\n",
        "            #convert it into RGB\n",
        "            image = image.convert(\"RGB\")\n",
        "        # transform the image\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXrReihMur2x"
      },
      "source": [
        "train_data = CassavaDataset(train_df, transform)\n",
        "valid_data = CassavaDataset(valid_df, transform)\n",
        "test_data = CassavaDataset(test_df, transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5pd8OT2uvKV",
        "outputId": "fa042e14-9136-4a91-c330-b540344486e2"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.5357, -1.5357, -1.5528,  ..., -1.3130, -1.2617, -1.2103],\n",
              "          [-1.5185, -1.5185, -1.5185,  ..., -1.2445, -1.2445, -1.2103],\n",
              "          [-1.5185, -1.5014, -1.5014,  ..., -1.2103, -1.1760, -1.1589],\n",
              "          ...,\n",
              "          [-1.3473, -1.3815, -1.4158,  ..., -1.0219, -1.2617, -1.3130],\n",
              "          [-1.3644, -1.4500, -1.4158,  ..., -1.1075, -1.3302, -1.3815],\n",
              "          [-1.3302, -1.3644, -1.4500,  ..., -1.1075, -1.3473, -1.4158]],\n",
              " \n",
              "         [[ 0.9580,  0.9580,  0.9755,  ..., -0.2325, -0.1275, -0.0574],\n",
              "          [ 0.9755,  0.9930,  1.0105,  ..., -0.0924, -0.0574, -0.0049],\n",
              "          [ 0.9755,  0.9930,  1.0280,  ..., -0.0049,  0.0301,  0.0476],\n",
              "          ...,\n",
              "          [ 0.6954,  0.6604,  0.6954,  ...,  1.2556,  1.0980,  1.0105],\n",
              "          [ 0.6954,  0.6429,  0.6954,  ...,  1.1856,  1.0280,  0.9580],\n",
              "          [ 0.7654,  0.7479,  0.6954,  ...,  1.1856,  1.0105,  0.9230]],\n",
              " \n",
              "         [[ 0.7228,  0.7228,  0.7402,  ..., -1.2119, -1.3513, -1.4210],\n",
              "          [ 0.7402,  0.7576,  0.7751,  ..., -1.2119, -1.3513, -1.4036],\n",
              "          [ 0.7402,  0.7576,  0.7751,  ..., -1.2990, -1.3164, -1.3339],\n",
              "          ...,\n",
              "          [ 0.3742,  0.3568,  0.3568,  ...,  1.1062,  0.9842,  0.9668],\n",
              "          [ 0.3916,  0.3045,  0.3219,  ...,  0.9668,  0.8448,  0.8274],\n",
              "          [ 0.4439,  0.3568,  0.2348,  ...,  0.8971,  0.7576,  0.7228]]]), 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne11WNPUuxJX"
      },
      "source": [
        "num_epoch = 10\n",
        "num_classes = 5\n",
        "batch_size = 64\n",
        "lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myer7v41uzbY"
      },
      "source": [
        "#Creating data loaders\n",
        "train_loader = DataLoader(dataset = train_data, \n",
        "                          batch_size = batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers = 0)\n",
        "\n",
        "valid_loader = DataLoader(dataset = valid_data, \n",
        "                          batch_size = batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers = 0)\n",
        "\n",
        "test_loader = DataLoader(dataset = test_data, \n",
        "                          batch_size = batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GbMZMy-u1Lb"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06l2JSNeu4CA"
      },
      "source": [
        "#convolutional neural network\n",
        "class Leaf_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Leaf_CNN, self).__init__()\n",
        "\n",
        "      self.cnn_layers = nn.Sequential(\n",
        "          \n",
        "        #defining a 2D convolution layer 1\n",
        "        nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "    \n",
        "        #defining a 2D convolution layer 2\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2), \n",
        "\n",
        "        #defining a 2D convolution layer 3\n",
        "        nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        #defining a 2D convolution layer 4\n",
        "        nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        \n",
        "      )\n",
        "\n",
        "      self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(0.2, inplace=True),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(0.2, inplace=True),\n",
        "            nn.Linear(64, 5),\n",
        "            ) \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = torch.mean(x, dim = 3)\n",
        "        x, _ = torch.max(x, dim = 2)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6X6jDiku8Aj"
      },
      "source": [
        "model = Leaf_CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KQo9iDqvAMa"
      },
      "source": [
        "#function for calculating the accuracy of the model\n",
        "def calc_accuracy(model, df):\n",
        "    model.eval()\n",
        "    path = df['path']\n",
        "    label = df['label']\n",
        "    count = 0\n",
        "    for i in range(len(path)):\n",
        "        image_path = path[i]\n",
        "        image_label = label[i]\n",
        "        image = Image.open(image_path)\n",
        "        image = transform(image)\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        model = model.to(device)\n",
        "        pred = model(image).argmax(1).item()\n",
        "        if pred == image_label:\n",
        "            count += 1\n",
        "    percent = count/len(path)\n",
        "    return percent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AaK0rI2Jroy"
      },
      "source": [
        "import time\n",
        "def train_model(model, train_loader, valid_loader, optimizer, criterion, epoch):\n",
        "    best_model = None\n",
        "    best_loss = float(\"inf\")\n",
        "    # if \"model.pth\" not in output_list:\n",
        "    train_losses, valid_losses = [], []\n",
        "    acc = []\n",
        "    for epoch in range(1, epoch + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            #for backward propagation\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()*len(data)\n",
        "\n",
        "        #updating the training loss\n",
        "        train_loss = train_loss/len(train_loader.sampler)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(data)\n",
        "                pred = (output.argmax(1) == target)\n",
        "                acc.append(sum(pred)/ len(pred))\n",
        "                \n",
        "                loss = criterion(output, target)\n",
        "                \n",
        "                valid_loss += loss.item()*len(data)\n",
        "                if valid_loss < best_loss:\n",
        "                    best_model = model\n",
        "                    best_loss = valid_loss\n",
        "\n",
        "        #Updating accuracy and validation loss\n",
        "        collection = sum(acc)/len(acc)\n",
        "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "        valid_losses.append(valid_loss)\n",
        "        print('Time: {:.3f}\\t Epoch: {} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.6f} \\t Acc: {:.2f}'\n",
        "              .format(time.time() - epoch_start_time, epoch, train_loss, valid_loss, collection))\n",
        "        num_collection = []\n",
        "    torch.save(best_model.state_dict(), \"./model.pth\")\n",
        "    \n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxzYCI6eJyAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2775b44-3a61-4a58-afb6-9f308deaaa05"
      },
      "source": [
        "best_model = train_model(model, train_loader, valid_loader, optim, criterion, num_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time: 8736.145\t Epoch: 1 \tTraining Loss: 1.004 \tValidation Loss: 1.200744 \t Acc: 0.57\n",
            "Time: 512.358\t Epoch: 2 \tTraining Loss: 0.882 \tValidation Loss: 1.361476 \t Acc: 0.61\n",
            "Time: 503.401\t Epoch: 3 \tTraining Loss: 0.815 \tValidation Loss: 0.881436 \t Acc: 0.63\n",
            "Time: 505.876\t Epoch: 4 \tTraining Loss: 0.781 \tValidation Loss: 0.855999 \t Acc: 0.65\n",
            "Time: 497.903\t Epoch: 5 \tTraining Loss: 0.726 \tValidation Loss: 0.946320 \t Acc: 0.66\n",
            "Time: 494.087\t Epoch: 6 \tTraining Loss: 0.706 \tValidation Loss: 0.699270 \t Acc: 0.67\n",
            "Time: 498.044\t Epoch: 7 \tTraining Loss: 0.657 \tValidation Loss: 0.789187 \t Acc: 0.68\n",
            "Time: 488.407\t Epoch: 8 \tTraining Loss: 0.724 \tValidation Loss: 0.710640 \t Acc: 0.69\n",
            "Time: 489.352\t Epoch: 9 \tTraining Loss: 0.662 \tValidation Loss: 0.803916 \t Acc: 0.69\n",
            "Time: 485.247\t Epoch: 10 \tTraining Loss: 0.602 \tValidation Loss: 0.610595 \t Acc: 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYllvwqLvIzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091154a9-d57a-498a-bcdf-a7d9c3a59a86"
      },
      "source": [
        "#accuracy on test data\n",
        "calc_accuracy(best_model, test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7542056074766356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgsz5PaVS7gp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}